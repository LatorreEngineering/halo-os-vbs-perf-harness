name: Halo.OS VBS Perf Harness CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      duration:
        description: 'Experiment duration (seconds)'
        required: false
        default: '120'
      scenario:
        description: 'Test scenario'
        required: false
        default: 'aeb_120kmh'
        type: choice
        options:
          - aeb_120kmh
          - lka_80kmh
          - parking

env:
  PYTHON_VERSION: '3.10'
  CACHE_VERSION: 'v4'
  MANIFEST_REPO_URL: 'https://gitee.com/haloos/manifests.git'
  MANIFEST_NAME: 'vbs.xml'

jobs:
  validate:
    runs-on: ubuntu-22.04
    steps:
      - uses: actions/checkout@v4
      - name: Install validation tools
        run: sudo apt-get update && sudo apt-get install -y libxml2-utils shellcheck
      - name: Validate XML manifests
        run: for f in manifests/*.xml; do xmllint --noout "$f"; done || exit 1
      - name: ShellCheck all scripts
        run: for f in ci/*.sh; do shellcheck "$f"; done

  lint-python:
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-22.04
    needs: validate
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - name: Run PyLint (non-blocking)
        continue-on-error: true
        run: |
          pip install pylint
          echo "Running PyLint (non-blocking)"
          for f in ci/*.py; do [ -f "$f" ] && pylint "$f"; done

  setup:
    runs-on: ubuntu-22.04
    needs: validate
    outputs:
      cache-key: ${{ steps.cache.outputs.key }}
    steps:
      - uses: actions/checkout@v4
      - name: Generate cache key
        id: cache
        run: |
          hash=$(find manifests requirements.txt -type f -exec sha256sum {} + 2>/dev/null | sha256sum | cut -d' ' -f1)
          echo "key=${{ env.CACHE_VERSION }}-${hash}" >> $GITHUB_OUTPUT
      - uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            venv/
          key: ${{ steps.cache.outputs.key }}
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - name: Install Python dependencies
        run: |
          python -m venv venv
          . venv/bin/activate
          pip install --upgrade pip
          [ -f requirements.txt ] && pip install -r requirements.txt
      - name: Run setup_env.sh
        run: |
          chmod +x ci/setup_env.sh
          ./ci/setup_env.sh

  build:
    runs-on: ubuntu-22.04
    needs: setup
    steps:
      - uses: actions/checkout@v4
      - uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            venv/
          key: ${{ needs.setup.outputs.cache-key }}
      - name: Build VBSPro
        env:
          GITEE_TOKEN: ${{ secrets.GITEE_TOKEN }}
        run: |
          chmod +x ci/build_halo.sh
          ./ci/build_halo.sh
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: vbspro-build
          path: build/
          retention-days: 7

  experiment:
    runs-on: ubuntu-22.04
    needs: build
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with:
          name: vbspro-build
          path: build/
      - name: Run performance experiment
        env:
          LD_LIBRARY_PATH: build/install/lib:$LD_LIBRARY_PATH
        run: |
          . venv/bin/activate
          mkdir -p results
          SCENARIO="${{ github.event.inputs.scenario || 'aeb_120kmh' }}"
          DURATION="${{ github.event.inputs.duration || '120' }}"
          mkdir -p "results/$SCENARIO"
          chmod +x ci/run_experiment.sh
          ./ci/run_experiment.sh "results/$SCENARIO" "$DURATION" --scenario "$SCENARIO"
      - name: Upload traces
        uses: actions/upload-artifact@v4
        with:
          name: experiment-traces
          path: results/
          retention-days: 7

  analyze:
    runs-on: ubuntu-22.04
    needs: experiment
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with:
          name: experiment-traces
          path: results/
      - name: Analyze traces
        run: |
          . venv/bin/activate
          for dir in results/*/; do
            jsonl="$dir/events.jsonl"
            if [ -f "$jsonl" ]; then
              echo "Analyzing $jsonl"
              python ci/analyze.py "$jsonl" --output "$dir/metrics.json"
            fi
          done
      - name: Upload metrics
        uses: actions/upload-artifact@v4
        with:
          name: perf-metrics
          path: results/
          retention-days: 30

  docker:
    runs-on: ubuntu-22.04
    needs: setup
    steps:
      - uses: actions/checkout@v4
      - uses: docker/setup-buildx-action@v3
      - uses: docker/build-push-action@v5
        with:
          context: .
          load: true
          tags: halo-perf:ci
      - name: Test Docker image
        run: docker run --rm halo-perf:ci python -c "import numpy, pandas; print('Docker ready')"

  summary:
    runs-on: ubuntu-22.04
    needs: [build, experiment, analyze, docker]
    if: always()
    steps:
      - name: Final CI Status
        run: |
          if [[ '${{ needs.build.result }}' == 'success' ]] && \
             [[ '${{ needs.experiment.result }}' == 'success' ]] && \
             [[ '${{ needs.analyze.result }}' == 'success' ]]; then
            echo "FULL PIPELINE SUCCESS: VBSPro built and metrics generated!"
          else
            echo "Some jobs failed â€” check artifacts and logs above."
            exit 1
          fi
