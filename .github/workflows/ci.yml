name: Halo.OS VBS Performance CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    # Nightly build at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      duration:
        description: 'Experiment duration (seconds)'
        required: false
        default: '120'
      scenario:
        description: 'Test scenario'
        required: false
        default: 'aeb_120kmh'
        type: choice
        options:
          - aeb_120kmh
          - lka_80kmh
          - parking

env:
  PYTHON_VERSION: '3.11'
  CACHE_VERSION: 'v4'
  MANIFEST_REPO_URL: 'https://gitee.com/haloos/manifests.git'
  MANIFEST_NAME: 'vbs.xml'

jobs:
  # ===========================================================================
  # Job 1: Validate Repository
  # ===========================================================================
  validate:
    name: Validate Repository
    runs-on: ubuntu-22.04
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Install validation tools
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y libxml2-utils shellcheck python3-venv
      
      - name: Validate XML manifests
        run: |
          echo "==> Validating XML manifests..."
          manifest_found=false
          
          # Check for any XML files in manifests/
          for manifest in manifests/*.xml 2>/dev/null; do
            if [ -f "$manifest" ]; then
              manifest_found=true
              echo "Checking: $manifest"
              if xmllint --noout "$manifest" 2>&1; then
                echo "âœ“ Valid: $manifest"
              else
                echo "âœ— Invalid: $manifest"
                exit 1
              fi
            fi
          done
          
          # It's OK if there are no local manifests (we use Gitee manifests)
          if [ "$manifest_found" = false ]; then
            echo "â„¹ No local manifests found (will use Gitee manifests)"
          fi
      
      - name: Validate Python scripts
        run: |
          echo "==> Checking Python syntax..."
          
          for script in ci/*.py 2>/dev/null; do
            if [ -f "$script" ]; then
              echo "Checking: $script"
              python3 -m py_compile "$script" || exit 1
              echo "âœ“ Valid: $script"
            fi
          done
      
      - name: Validate Bash scripts
        run: |
          echo "==> Checking Bash syntax..."
          
          for script in ci/*.sh 2>/dev/null; do
            if [ -f "$script" ]; then
              echo "Checking: $script"
              # SC1090: Can't follow non-constant source
              # SC1091: Not following sourced file
              # SC2016: Expressions don't expand in single quotes (expected for repo forall)
              shellcheck -e SC1090,SC1091,SC2016 "$script" || exit 1
              echo "âœ“ Valid: $script"
            fi
          done
      
      - name: Check required files
        run: |
          echo "==> Checking required files..."
          
          required_files=(
            "ci/build_halo.sh"
            "requirements.txt"
            "Dockerfile"
            "README.md"
          )
          
          missing=0
          for file in "${required_files[@]}"; do
            if [ -f "$file" ]; then
              echo "âœ“ Found: $file"
            else
              echo "âœ— Missing: $file"
              ((missing++))
            fi
          done
          
          if [ $missing -gt 0 ]; then
            echo "âœ— Missing $missing required file(s)"
            exit 1
          fi
          
          echo "âœ“ All required files present"

  # ===========================================================================
  # Job 2: Setup Environment
  # ===========================================================================
  setup:
    name: Setup Environment
    runs-on: ubuntu-22.04
    needs: validate
    outputs:
      cache-key: ${{ steps.cache-keys.outputs.deps }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Generate cache keys
        id: cache-keys
        run: |
          # Hash requirements.txt for cache key
          if [ -f requirements.txt ]; then
            DEPS_HASH=$(sha256sum requirements.txt | cut -d' ' -f1)
          else
            DEPS_HASH="no-requirements"
          fi
          
          CACHE_KEY="${{ env.CACHE_VERSION }}-deps-${DEPS_HASH}"
          echo "deps=${CACHE_KEY}" >> $GITHUB_OUTPUT
          echo "Cache key: ${CACHE_KEY}"
      
      - name: Cache Python dependencies
        id: cache-deps
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            venv
          key: ${{ steps.cache-keys.outputs.deps }}
          restore-keys: |
            ${{ env.CACHE_VERSION }}-deps-
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install Python dependencies
        run: |
          python3 -m venv venv
          source venv/bin/activate
          pip install --upgrade pip setuptools wheel
          
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi

  # ===========================================================================
  # Job 3: Build Halo.OS (VBSPro)
  # ===========================================================================
  build:
    name: Build Halo.OS VBSPro
    runs-on: ubuntu-22.04
    needs: setup
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Restore Python cache
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            venv
          key: ${{ needs.setup.outputs.cache-key }}
          restore-keys: |
            ${{ env.CACHE_VERSION }}-deps-
      
      - name: Build VBSPro with instrumentation
        env:
          GITEE_TOKEN: ${{ secrets.GITEE_TOKEN || '' }}
          GITEE_SSH_KEY: ${{ secrets.GITEE_SSH_KEY || '' }}
          MANIFEST_REPO_URL: ${{ env.MANIFEST_REPO_URL }}
          MANIFEST_NAME: ${{ env.MANIFEST_NAME }}
        run: |
          chmod +x ci/build_halo.sh
          ./ci/build_halo.sh --jobs $(nproc)
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: halo-vbspro-build-${{ github.sha }}
          path: |
            build/
            !build/**/*.o
            !build/**/*.d
          retention-days: 7
      
      - name: Upload build logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: build-logs-${{ github.sha }}
          path: logs/
          retention-days: 3

  # ===========================================================================
  # Job 4: Run Experiments
  # ===========================================================================
  experiment:
    name: Run Experiments
    runs-on: ubuntu-22.04
    needs: build
    if: success()
    strategy:
      fail-fast: false
      matrix:
        scenario:
          - aeb_120kmh
        include:
          - scenario: aeb_120kmh
            duration: 120
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: halo-vbspro-build-${{ github.sha }}
          path: build/
      
      - name: Make binaries executable
        run: |
          find build -type f -name "vbs_*" -exec chmod +x {} \; 2>/dev/null || true
          find build -type f -name "*.sh" -exec chmod +x {} \; 2>/dev/null || true
      
      - name: Setup experiment environment
        run: |
          # For CI, we'll create mock experiment data since we can't run actual hardware
          mkdir -p results/ci_${{ matrix.scenario }}_$(date +%Y%m%d_%H%M%S)
      
      - name: Generate mock experiment data
        run: |
          # Create sample trace data for CI testing
          RUN_DIR="results/ci_${{ matrix.scenario }}_$(date +%Y%m%d_%H%M%S)"
          mkdir -p "$RUN_DIR"
          
          # Generate mock events.jsonl using echo (avoiding heredoc in YAML)
          echo '{"timestamp_ns": 1000000000, "event_name": "halo_camera_frame_received", "fields": {"frame_id": 1}}' > "$RUN_DIR/events.jsonl"
          echo '{"timestamp_ns": 1102400000, "event_name": "halo_brake_actuated", "fields": {"frame_id": 1}}' >> "$RUN_DIR/events.jsonl"
          echo '{"timestamp_ns": 1200000000, "event_name": "halo_camera_frame_received", "fields": {"frame_id": 2}}' >> "$RUN_DIR/events.jsonl"
          echo '{"timestamp_ns": 1305000000, "event_name": "halo_brake_actuated", "fields": {"frame_id": 2}}' >> "$RUN_DIR/events.jsonl"
          echo '{"timestamp_ns": 2000000000, "event_name": "halo_npu_inference_start", "fields": {"inference_id": 1}}' >> "$RUN_DIR/events.jsonl"
          echo '{"timestamp_ns": 2020000000, "event_name": "halo_npu_inference_end", "fields": {"inference_id": 1}}' >> "$RUN_DIR/events.jsonl"
          
          echo "Mock experiment data created in: $RUN_DIR"
          echo "run_dir=$RUN_DIR" >> "$GITHUB_OUTPUT"
        id: mock_data
      
      - name: Upload experiment results
        uses: actions/upload-artifact@v4
        with:
          name: experiment-${{ matrix.scenario }}-${{ github.sha }}
          path: results/
          retention-days: 7

  # ===========================================================================
  # Job 5: Analyze Results
  # ===========================================================================
  analyze:
    name: Analyze Results
    runs-on: ubuntu-22.04
    needs: experiment
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Restore Python cache
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            venv
          key: ${{ needs.setup.outputs.cache-key }}
      
      - name: Install Python dependencies
        run: |
          if [ -d venv ]; then
            source venv/bin/activate
          else
            python3 -m venv venv
            source venv/bin/activate
            pip install -r requirements.txt
          fi
      
      - name: Download experiment results
        uses: actions/download-artifact@v4
        with:
          pattern: experiment-*
          path: results/
      
      - name: Run analysis
        run: |
          source venv/bin/activate
          
          # Find all events.jsonl files
          for events_file in results/**/events.jsonl; do
            if [ -f "$events_file" ]; then
              echo "Analyzing: $events_file"
              output_dir=$(dirname "$events_file")
              
              if [ -f ci/analyze_vbs.py ]; then
                python3 ci/analyze_vbs.py "$events_file" --output "$output_dir" || echo "Analysis failed for $events_file"
              else
                echo "analyze_vbs.py not found, skipping analysis"
              fi
            fi
          done
      
      - name: Generate summary report
        run: |
          cat > results/ci_summary.md << 'ENDOFFILE'
# Halo.OS VBS Performance CI Summary

## Build Information
- **Commit**: ${{ github.sha }}
- **Branch**: ${{ github.ref_name }}
ENDOFFILE
          
          echo "- **Date**: $(date)" >> results/ci_summary.md
          echo "- **Workflow**: ${{ github.workflow }}" >> results/ci_summary.md
          echo "" >> results/ci_summary.md
          echo "## Experiment Results" >> results/ci_summary.md
          echo "" >> results/ci_summary.md
          
          # Append analysis reports if they exist
          for report in results/**/analysis_report.txt; do
            if [ -f "$report" ]; then
              scenario=$(basename $(dirname "$report"))
              echo "### ${scenario}" >> results/ci_summary.md
              echo '```' >> results/ci_summary.md
              cat "$report" >> results/ci_summary.md
              echo '```' >> results/ci_summary.md
              echo "" >> results/ci_summary.md
            fi
          done
      
      - name: Upload analysis results
        uses: actions/upload-artifact@v4
        with:
          name: analysis-results-${{ github.sha }}
          path: |
            results/**/*.txt
            results/**/*.png
            results/**/*.md
          retention-days: 30

  # ===========================================================================
  # Job 6: Docker Build Test
  # ===========================================================================
  docker:
    name: Docker Build Test
    runs-on: ubuntu-22.04
    needs: validate
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: false
          tags: halo-os-perf-harness:ci
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Test Docker image
        run: |
          docker run --rm halo-os-perf-harness:ci \
            python3 -c "import sys; print(f'Python {sys.version}'); import numpy, pandas; print('Dependencies OK')"

  # ===========================================================================
  # Job 7: CI Success Check
  # ===========================================================================
  ci-success:
    name: CI Pipeline Complete
    runs-on: ubuntu-22.04
    needs: [validate, setup, build, experiment, analyze, docker]
    if: always()
    steps:
      - name: Check job statuses
        run: |
          echo "Checking CI job statuses..."
          
          # Critical jobs that must pass
          if [ "${{ needs.validate.result }}" != "success" ]; then
            echo "âœ— Validation failed"
            exit 1
          fi
          
          if [ "${{ needs.setup.result }}" != "success" ]; then
            echo "âœ— Setup failed"
            exit 1
          fi
          
          if [ "${{ needs.build.result }}" != "success" ]; then
            echo "âœ— Build failed"
            exit 1
          fi
          
          if [ "${{ needs.docker.result }}" != "success" ]; then
            echo "âœ— Docker build failed"
            exit 1
          fi
          
          # Experiment and analysis can have warnings
          echo "âœ… All critical jobs passed!"
          echo "ðŸ“Š Check artifacts for detailed results"
      
      - name: Report success
        run: |
          echo "========================================" 
          echo "âœ… CI Pipeline Completed Successfully"
          echo "========================================"
          echo ""
          echo "Build Artifacts: halo-vbspro-build-${{ github.sha }}"
          echo "Analysis Results: analysis-results-${{ github.sha }}"
          echo ""
          echo "Next steps:"
          echo "1. Download artifacts to examine build outputs"
          echo "2. Review analysis reports for performance metrics"
          echo "3. Run experiments on real hardware for validation"
